version: '3.8'

services:
  # TiDB PD (Placement Driver)
  pd:
    image: pingcap/pd:latest
    container_name: tidb-pd
    ports:
      - "2379:2379"
    command:
      - --name=pd
      - --client-urls=http://0.0.0.0:2379
      - --peer-urls=http://0.0.0.0:2380
      - --advertise-client-urls=http://pd:2379
      - --advertise-peer-urls=http://pd:2380
      - --initial-cluster=pd=http://pd:2380
      - --data-dir=/data/pd
    volumes:
      - pd-data:/data/pd
    networks:
      - tidb-network
    restart: unless-stopped

  # TiKV Storage
  tikv:
    image: pingcap/tikv:latest
    container_name: tidb-tikv
    command:
      - --addr=0.0.0.0:20160
      - --advertise-addr=tikv:20160
      - --pd=pd:2379
      - --data-dir=/data/tikv
    volumes:
      - tikv-data:/data/tikv
    networks:
      - tidb-network
    depends_on:
      - pd
    restart: unless-stopped

  # TiDB Server
  tidb:
    image: pingcap/tidb:latest
    container_name: tidb-server
    ports:
      - "4000:4000"
      - "10080:10080"
    command:
      - --store=tikv
      - --path=pd:2379
      - --advertise-address=tidb
    networks:
      - tidb-network
    depends_on:
      - tikv
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nc", "-z", "127.0.0.1", "4000"]
      interval: 10s
      timeout: 5s
      retries: 10

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - tidb-network
    restart: unless-stopped

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    networks:
      - tidb-network
    depends_on:
      - zookeeper
    restart: unless-stopped

  # TiCDC (Change Data Capture)
  ticdc:
    image: pingcap/ticdc:latest
    container_name: ticdc
    command:
      - server
      - --addr=0.0.0.0:8300
      - --pd=http://pd:2379
      - --log-file=/logs/ticdc.log
      - --log-level=info
    ports:
      - "8300:8300"
    volumes:
      - ticdc-data:/data
      - ticdc-logs:/logs
    networks:
      - tidb-network
    depends_on:
      - tidb
      - kafka
    restart: unless-stopped

  # Database Initialization
  db-init:
    image: mysql:8.0
    container_name: db-init
    volumes:
      - ./sql/schema.sql:/docker-entrypoint-initdb.d/schema.sql
      - ./sql/seed.sql:/docker-entrypoint-initdb.d/seed.sql
      - ./scripts/init.sh:/init.sh
    entrypoint: ["/bin/bash", "/init.sh"]
    networks:
      - tidb-network
    depends_on:
      tidb:
        condition: service_healthy

  # CDC Task Setup
  cdc-setup:
    image: curlimages/curl:latest
    container_name: cdc-setup
    volumes:
      - ./scripts/setup-cdc.sh:/setup-cdc.sh
    entrypoint: ["/bin/sh", "/setup-cdc.sh"]
    networks:
      - tidb-network
    depends_on:
      - ticdc
      - db-init

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - es-data:/usr/share/elasticsearch/data
    networks:
      - tidb-network
    restart: unless-stopped

  # Node.js Consumer
  consumer:
    build:
      context: ./consumer
      dockerfile: Dockerfile
    container_name: cdc-consumer
    environment:
      - KAFKA_BROKER=kafka:29092
      - KAFKA_TOPIC=tidb-cdc-events
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - PROMETHEUS_PORT=9091
    ports:
      - "9091:9091"
    volumes:
      - ./consumer:/app
      - /app/node_modules
    networks:
      - tidb-network
    depends_on:
      - kafka
      - elasticsearch
    restart: unless-stopped

  # Filebeat for log shipping
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.10.2
    container_name: filebeat
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ticdc-logs:/logs:ro
    networks:
      - tidb-network
    depends_on:
      - elasticsearch
    restart: unless-stopped

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - tidb-network
    restart: unless-stopped

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    networks:
      - tidb-network
    depends_on:
      - prometheus
      - elasticsearch
    restart: unless-stopped

networks:
  tidb-network:
    driver: bridge

volumes:
  pd-data:
  tikv-data:
  ticdc-data:
  ticdc-logs:
  es-data:
  prometheus-data:
  grafana-data: